# Fine-Tuning-Large-Language-Model-Falcon-7b

<img src="Screenshots/Falcon.jpg" width="100%">

## Requirements 

##### 1) Decent GPU with minimum 6GB VRAM
##### 2) Jupyter Notebook
##### 3) TREC CASsT Dataset

## Concepts Used

- PEFT: Parameter Efficient Fine Tuning
- LoRA: Low Rank Adaptation
- QLoRA: Quantization & Low Rank Adapters
- Evaluation Metrics
  - BLEU: Bilingual Evaluation Understudy
  - ROUGE: Recall-Oriented Understudy for Gisting Evaluation
  - BERTScore
  - MoverScore

 &rarr; Refer to the 3 [PPTs](PPTs/) 


